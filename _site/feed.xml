<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://www.helloted.com/feed.xml" rel="self" type="application/atom+xml" /><link href="http://www.helloted.com/" rel="alternate" type="text/html" /><updated>2024-07-26T17:46:29+08:00</updated><id>http://www.helloted.com/feed.xml</id><title type="html">Helloted Blog</title><subtitle>曹浩之Helloted的技术博客，用于记录一些技术成长过程中的技术分享，包括客户端iOS/Android，后台Pyhon/Java，跨平台开发Flutter</subtitle><entry><title type="html">Golang-Map</title><link href="http://www.helloted.com/golang/2023/01/05/map/" rel="alternate" type="text/html" title="Golang-Map" /><published>2023-01-05T20:00:00+08:00</published><updated>2023-01-05T20:00:00+08:00</updated><id>http://www.helloted.com/golang/2023/01/05/map</id><content type="html" xml:base="http://www.helloted.com/golang/2023/01/05/map/">&lt;h3 id=&quot;1-map的本质&quot;&gt;&lt;strong&gt;1、 map的本质&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;golang中的map是一个指针。当执行语句 make(map[k]v, hint) 的时候，其实是调用了 makemap 函数，返回了一个指针&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// makemap implements Go map creation for make(map[k]v, hint).
func makemap(t *maptype, hint int, h *hmap) *hmap    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;hmap是map的底层：是 hashmap 的“缩写”，但是hmap还不是主要存储key value的结构，hmap做的是一些map结构的基本设定。&lt;/p&gt;

&lt;h3 id=&quot;2结构&quot;&gt;&lt;strong&gt;2、结构&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 id=&quot;21-实现原理&quot;&gt;&lt;strong&gt;2.1 实现原理&lt;/strong&gt;&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Go中的map是一个指针，占用8个字节，指向hmap结构体; 源码src/runtime/map.go中可以看到map的底层结构&lt;/li&gt;
  &lt;li&gt;每个map的底层结构是hmap，hmap包含若干个结构为bmap的bucket数组。每个bucket底层都采用链表结构&lt;/li&gt;
  &lt;li&gt;每个 bucket 中存储的是 Hash 值低 bit 位数值相同的元素，默认的元素个数为 BUCKETSIZE（值为 8，Go 1.17 版本中在 $GOROOT/src/cmd/compile/internal/reflectdata/reflect.go 中定义，与runtime/map.go 中常量 bucketCnt 保持一致）&lt;/li&gt;
  &lt;li&gt;当某个 bucket（比如 buckets[0]) 的 8 个空槽 slot）都填满了，且 map 尚未达到扩容的条件的情况下，运行时会建立 overflow bucket，并将这个 overflow bucket 挂在上面 bucket（如 buckets[0]）末尾的 overflow 指针上，这样两个 buckets 形成了一个链表结构，直到下一次 map 扩容之前，这个结构都会一直存在&lt;/li&gt;
  &lt;li&gt;map 结构，key和value单独排列在一起可以减少结构体对齐填充，减少内存浪费&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/64.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;22-hmap&quot;&gt;&lt;strong&gt;2.2 hmap&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;map本质是hash表（hmap），指向一堆桶（buckets）用来承接数据，每个桶（bmap）能存8组k/v。&lt;/p&gt;

&lt;p&gt;当有数据读写时，会用key的hash找到对应的桶，hash值低8位用来定位桶，高8位用来定位桶内位置，bmap里记录了tophash数组（hash的高8位），方便桶内定位。&lt;/p&gt;

&lt;p&gt;hash表就会有哈希冲突的问题（不同key的hash值一样，即hash后都指向同一个桶），为此map使用桶后链一个溢出桶（overflow）链表来解决当桶8个单元都满了，但还有数据需要存入此桶的问题。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// hmap的基础数据结构
type hmap struct {
	count     int	 // 元素的个数 == len()返回的值，必须放在第一个位置因为 len函数需要使用，所以map的len()时间复杂度是O(1)
	flags     uint8  // map的操作状态，如当前是否有别的线程正在写map、当前是否为相同大小的增长（扩容/缩容？）
	B         uint8  // hash桶buckets的数量为2^B个
	noverflow uint16 // 溢出的桶的数量的近似值
	hash0     uint32 // hash种子

	buckets    unsafe.Pointer // 指向2^B个桶组成的数组的指针，数据存在这里
	oldbuckets unsafe.Pointer // 指向扩容前的旧buckets数组，只在map增长时有效
	nevacuate  uintptr        // 计数器，标示扩容后搬迁的进度

	extra *mapextra // 保存溢出桶的链表和未使用的溢出桶数组的首地址
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/65.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/66.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;23-bmap&quot;&gt;&lt;strong&gt;2.3 bmap&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;bmap 就是我们常说的“桶”，桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果是“一类”的。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（tophash数组记录了key的高8位，方便key用来查找bmap，以及bmap中定位keyvaule）。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;type bmap struct {
    tophash [bucketCnt]uint8
    // len为8的数组
    // 用来快速定位key是否在这个bmap中
    // 桶的槽位数组，一个桶最多8个槽位，如果key所在的槽位在tophash中，则代表该key在这个桶中
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;但这只是表面(src/runtime/hashmap.go)的结构，编译期间会给它加料，动态地创建一个新的结构：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;type bmap struct {
    topbits  [8]uint8
    keys     [8]keytype
    values   [8]valuetype
    pad      uintptr
    overflow uintptr
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意到 key 和 value 是各自放在一起的，并不是 key/value/key/value/… 这样的形式。源码里说明这样的好处是在某些情况下可以省略掉 padding字段，节省内存空间。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/67.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;24-tophash&quot;&gt;&lt;strong&gt;2.4 tophash&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;tophash是一个长度为8的数组，记录了key的高8位，方便桶内定位。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;向 map 插入一条数据，或者是从 map 按 key 查询数据的时候，运行时都会使用哈希函数对 key 做哈希运算，并获得一个哈希值（hashcode）&lt;/li&gt;
  &lt;li&gt;运行时会把 hashcode“一分为二”来看待，其中低位区的值用于选定 bucket，高位区的值用于在某个 bucket 中确定 key 的位置&lt;/li&gt;
  &lt;li&gt;每个 bucket 的 tophash 区域其实是用来快速定位 key 位置的，避免了逐个 key 进行比较这种代价较大的操作&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/68.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每一个tophash唯一对应一个K/V对。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/69.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;tophash是一个长度为8的数组，它不仅仅用来存放key的哈希高8位，在不同场景下它还可以标记迁移状态，bucket是否为空等。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当tophash对应的K/V被使用时，存的是key的哈希值的高8位；&lt;/li&gt;
  &lt;li&gt;当tophash对应的K/V未被使用时，存的是K/V对应位置的状态。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-go-map的扩容缩容&quot;&gt;3. go map的扩容缩容&lt;/h3&gt;

&lt;h4 id=&quot;31扩容过程&quot;&gt;&lt;strong&gt;3.1扩容过程&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;主要是由于哈希碰撞问题&lt;/p&gt;

&lt;p&gt;​    &lt;img src=&quot;/img/Simple_2/70.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;什么情况下会map扩容呢：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;溢出桶太多时会导致严重的性能下降&lt;/li&gt;
  &lt;li&gt;runtime.mapassign()可能会触发扩容的情况
    &lt;ul&gt;
      &lt;li&gt;装载因子超过6.5个（平均每个槽6.5个key）&lt;/li&gt;
      &lt;li&gt;使用太多溢出桶（溢出桶超过了普通桶）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;map的两种扩容类型:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;等量扩容（整理）：数据不多但是溢出桶太多了，使数据更紧凑&lt;/li&gt;
  &lt;li&gt;翻倍扩容：数据太多了增加普通桶的数量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;map的扩容过程：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;步骤一&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;创建一组新桶&lt;/li&gt;
  &lt;li&gt;oldbuckets指向原有的桶数组&lt;/li&gt;
  &lt;li&gt;buckets指向新的桶数组&lt;/li&gt;
  &lt;li&gt;把map标记为扩容状态&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;​    &lt;img src=&quot;/img/Simple_2/71.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;步骤二&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将所有的数据从旧桶驱逐到新桶&lt;/li&gt;
  &lt;li&gt;采用渐进式驱逐&lt;strong&gt;（好多技术都有这种思想，比如redis的rehash）&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;每次操作一个旧桶的时，将旧数据驱逐到新桶&lt;/li&gt;
  &lt;li&gt;读取时不进行驱逐，只判断读取新桶还是旧桶&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;​    &lt;img src=&quot;/img/Simple_2/72.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;步骤三&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;所有的旧桶驱逐完成后&lt;/li&gt;
  &lt;li&gt;oldbuckets回收&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;​     &lt;img src=&quot;/img/Simple_2/73.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;装载系数或者溢出桶的增加，会触发map扩容&lt;/li&gt;
  &lt;li&gt;“扩容”可能并不是增加桶的数量，而是整理数据，使数据更加紧凑&lt;/li&gt;
  &lt;li&gt;map扩容采用渐进式，桶被操作时才会重新分配&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;32-扩容缩容的基本原理&quot;&gt;&lt;strong&gt;3.2 扩容缩容的基本原理&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;go map的扩容缩容都是grow相关的函数，这里扩容是真的，缩容是伪缩容，后面我会解释。我们先看下触发条件：&lt;/p&gt;

&lt;p&gt;触发 map 扩容的时机：在向 map 插入新 key 的时候，会进行条件检测，符合下面这 2 个条件，就会触发扩容：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;装载因子超过阈值，源码里定义的阈值是 6.5。&lt;/li&gt;
  &lt;li&gt;overflow 的 bucket 数量过多：当 B 小于 15，也就是 bucket 总数 2^B 小于 2^15 时，如果 overflow 的 bucket 数量超过 2^B；当 B &amp;gt;= 15，也就是 bucket 总数 2^B 大于等于 2^15，如果 overflow 的 bucket 数量超过 2^15。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;map只在插入元素即mapassign()函数中对是否扩容缩容进行触发，条件即是上面这段代码：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;条件1：当前不处在growing状态&lt;/li&gt;
  &lt;li&gt;条件2-1：触发扩容：map的数据量count大于hash桶数量(2B)*6.5。注意这里的(2B)只是hash数组大小，不包括溢出的桶&lt;/li&gt;
  &lt;li&gt;条件2-2：触发缩容：溢出的桶数量noverflow&amp;gt;=32768(1«15)或者&amp;gt;=hash数组大小。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;仔细观察触发的代码，扩容和缩容是同一个函数，这是怎么做到的呢？在hashGrow()开始，会先判断是否满足扩容条件，如果满足就表明这次是扩容，不满足就一定是缩容条件触发了。扩容和缩容剩下的逻辑，主要区别就在于容量变化，就是hmap.B参数，扩容时B+1则hash表容量扩大1倍，缩容时hash表容量不变。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;h.oldbuckets：指向旧的hash数组，即当前的h.buckets&lt;/li&gt;
  &lt;li&gt;h.buckets：指向新创建的hash数组&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;到这里触发的主要工作已经完成，接下来就是怎么把元素搬迁到新hash表里了。如果现在就一次全量搬迁过去，显然接下来会有比较长的一段时间map被占用（不支持并发）。所以搬迁的工作是异步增量搬迁的。&lt;/p&gt;

&lt;p&gt;在插入和删除的函数内都有下面一段代码用于在每次插入和删除操作时，执行一次搬迁工作：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; if h.growing() { // 当前处于搬迁状态
		growWork(t, h, bucket) // 调用搬迁函数
	}
	
func growWork(t *maptype, h *hmap, bucket uintptr) {
	// 将当前需要处理的桶搬迁
	evacuate(t, h, bucket&amp;amp;h.oldbucketmask())

	if h.growing() { // 再多搬迁一个桶
		evacuate(t, h, h.nevacuate)
	}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;每执行一次插入或删除，都会调用growWork搬迁0~2个hash桶（有可能这次需要搬迁的2个桶在此之前都被搬过了）&lt;/li&gt;
  &lt;li&gt;搬迁是以hash桶为单位的，包含对应的hash桶和这个桶的溢出链表&lt;/li&gt;
  &lt;li&gt;被delete掉的元素(emptyone标志)会被舍弃（这是缩容的关键）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;33-为什么叫伪缩容如何实现真缩容&quot;&gt;&lt;strong&gt;3.3 为什么叫“伪缩容”？如何实现“真缩容”？&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;现在可以解释为什么我把map的缩容叫做伪缩容了：因为缩容仅仅针对溢出桶太多的情况，触发缩容时hash数组的大小不变，即hash数组所占用的空间只增不减。也就是说，如果我们把一个已经增长到很大的map的元素挨个全部删除掉，hash表所占用的内存空间也不会被释放。&lt;/p&gt;

&lt;p&gt;所以如果要实现“真缩容”，需自己实现缩容搬迁，即创建一个较小的map，将需要缩容的map的元素挨个搬迁过来：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// go map缩容代码示例
myMap := make(map[int]int, 1000000)

// 假设这里我们对bigMap做了很多次插入，之后又做了很多次删除，此时bigMap的元素数量远小于hash表大小
// 接下来我们开始缩容
smallMap := make(map[int]int, len(myMap))
for k, v := range myMap {
    smallMap[k] = v
}
myMap = smallMap // 缩容完成，原来的map被我们丢弃，交给gc去清理
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Ted</name></author><category term="Golang" /><summary type="html">1、 map的本质</summary></entry><entry><title type="html">数据库架构之Buffer Pool</title><link href="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/12/10/buffer/" rel="alternate" type="text/html" title="数据库架构之Buffer Pool" /><published>2022-12-10T20:00:00+08:00</published><updated>2022-12-10T20:00:00+08:00</updated><id>http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/12/10/buffer</id><content type="html" xml:base="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/12/10/buffer/">&lt;h3 id=&quot;1概念&quot;&gt;&lt;strong&gt;1、概念&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;InnoDB的Buffer Pool（缓冲池）是MySQL数据库中非常重要的一个组件，它主要用于缓存数据和索引，以提高数据库的性能。&lt;/p&gt;

&lt;p&gt;以下是Buffer Pool的主要作用：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据缓存：当你查询一个数据行时，InnoDB首先会在Buffer Pool中查找这个数据行。如果找到，那么就直接从内存中读取，这比从磁盘读取要快得多。如果在Buffer Pool中没有找到，那么InnoDB会从磁盘读取这个数据行，并将其放入Buffer Pool中，以便下次查询时能够直接从内存中读取。&lt;/li&gt;
  &lt;li&gt;索引缓存：除了数据行，InnoDB还会在Buffer Pool中缓存索引。这样，当你执行一个需要使用索引的查询时，InnoDB可以直接从内存中读取索引，而不需要从磁盘读取。&lt;/li&gt;
  &lt;li&gt;写操作的缓存：当你执行一个写操作（如INSERT、UPDATE或DELETE）时，InnoDB会先将修改写入到Buffer Pool中，然后在适当的时机（如在事务提交时或在做Checkpoint时）再将这些修改写入到磁盘。这种方式可以减少磁盘I/O操作，从而提高性能。&lt;/li&gt;
  &lt;li&gt;读写操作的并发控制：Buffer Pool中的每一个数据页都有对应的锁和读写控制机制，这样可以支持高并发的读写操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总的来说，InnoDB的Buffer Pool是一个非常重要的性能优化组件，它通过缓存数据和索引，以及优化磁盘I/O操作，来提高数据库的性能。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/61.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结&lt;/p&gt;

&lt;p&gt;Buffer Pool就是数据库的一个内存组件，里面缓存了磁盘上的真实数据，然后我们的系统对数据库执行的增删改操作，其实主要就是对这个内存数据结构中的缓存数据执行的。通过这种方式，保证每个更新请求，尽量就是只更新内存，然后往磁盘顺序写日志文件。&lt;/p&gt;

&lt;p&gt;更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是比较高的，因为顺序写磁盘文件，他的性能要远高于随机读写磁盘文件。&lt;/p&gt;

&lt;h3 id=&quot;2buffer-pool的工作流程&quot;&gt;&lt;strong&gt;2、buffer pool的工作流程&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;这条 SQL 语句的执行步骤大致是这样子的&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;innodb 存储引擎会在缓冲池中查找 id=1 的这条数据是否存在&lt;/li&gt;
  &lt;li&gt;发现不存在，那么就会去磁盘中加载，并将其存放在缓冲池中&lt;/li&gt;
  &lt;li&gt;该条记录会被加上一个独占锁&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/62.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;21--buffer-pool-vs-查询缓存&quot;&gt;&lt;strong&gt;2.1  buffer pool VS 查询缓存&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;在mysql8.0的版本中，已经将查询缓存模块删除了。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果将Mysql分为Server层和存储引擎层两大部分，那么Qcache位于Server层，Buffer Pool位于存储引擎层。&lt;/p&gt;

&lt;p&gt;　　如果你的Mysql 查询缓存功能是打开的，那么当一个sql进入Mysql Server之后，Mysql Server首先会从查询缓存中查看是否曾经执行过这个SQL，如果曾经执行过的话，曾经执行的查询结果之前会以key-value的形式&lt;/p&gt;

&lt;p&gt;保存在查询缓存中。key是sql语句，value是查询结果。我们将这个过程称为查询缓存！&lt;/p&gt;

&lt;p&gt;　　如果查询缓存中没有你要找的数据的话，MySQL才会执行后续的逻辑，通过存储引擎将数据检索出来。并且查询缓存会被shared cache for sessions，是的，它会被所有的session共享。&lt;/p&gt;

&lt;p&gt;　　MySQL查询缓存是查询结果缓存。它将以SEL开头的查询与哈希表进行比较，如果匹配，则返回上一次查询的结果。进行匹配时，查询必须逐字节匹配，例如 SELECT * FROM t1; 不等于select * from t1;，此外，一些不确定的查询结果无法被缓存，任何对表的修改都会导致这些表的所有缓存无效(只要有一个sql update了该表，那么表的查询缓存就会失效)。因此，适用于查询缓存的最理想的方案是只读，特别是需要检查数百万行后仅返回数行的复杂查询。如果你的查询符合这样一个特点，开启查询缓存会提升你的查询性能。&lt;/p&gt;

&lt;p&gt;　　MySQL查询缓存的目的是为了提升查询性能，但它本身也是有性能开销的。需要在合适的业务场景下（读写压力模型）使用，不合适的业务场景不但不能提升查询性能，查询缓存反而会变成MySQL的瓶颈。&lt;/p&gt;

&lt;p&gt;查询缓存的开销主要有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;读查询在开始前必须先检查是否命中缓存；&lt;/li&gt;
  &lt;li&gt;如果这个读查询可以被缓存，那么当完成执行后，MySQL若发现查询缓存中没有这个查询，会将其结果存入查询缓存，这会带来额外的系统消耗；&lt;/li&gt;
  &lt;li&gt;当向某个表写入数据的时候，MySQL必须将对应表的所有缓存都设置失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;查询缓存的缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先，查询缓存的效果取决于缓存的命中率，只有命中缓存的查询效果才能有改善，因此无法预测其性能。只要有一个sql update了该表，那么表的查询缓存就会失效，所以当你的业务对表CRUD的比例不相上下，那么查询缓存may be会影响应用的吞吐效率。&lt;/li&gt;
  &lt;li&gt;其次，查询缓存的另一个大问题是它受到单个互斥锁的保护。在具有多个内核的服务器上，大量查询会导致大量的互斥锁争用。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;在mysql8.0的版本中，已经将查询缓存模块删除了。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;22--undo-日志文件记录数据被修改前的样子&quot;&gt;&lt;strong&gt;2.2  undo 日志文件：记录数据被修改前的样子&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;在准备更新一条语句的时候，该条语句会先被加载到 Buffer pool 中了，同时，在将该条语句加载到 Buffer Pool 中的时候同时会往 undo 日志文件中插入一条日志，也就是将 id=1 的这条记录的原来的值记录下来。&lt;/p&gt;

&lt;p&gt;这样做的目的是什么？&lt;/p&gt;

&lt;p&gt;Innodb 存储引擎的最大特点就是支持事务，如果本次更新失败，也就是事务提交失败，那么该事务中的所有的操作都必须回滚到执行前的样子，也就是说当事务失败的时候，也不会对原始数据有影响，&lt;/p&gt;

&lt;h4 id=&quot;23-redo-日志文件记录数据被修改后的样子&quot;&gt;&lt;strong&gt;2.3 redo 日志文件：记录数据被修改后的样子&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;redo 日志文件是 InnoDB 特有的，他是存储引擎级别的，不是 MySQL 级别的&lt;/p&gt;

&lt;p&gt;redo 记录的是数据修改之后的值，不管事务是否提交都会记录下来。MySQL 为了提高效率，所以将这些操作都先放在内存中redo log buffer去完成，然后会在某个时机将其持久化到磁盘中。如果 MySQL 真的宕机了，那么没关系的，因为 MySQL 会认为本次事务是失败的，所以数据依旧是更新前的样子，并不会有任何的影响。&lt;/p&gt;

&lt;p&gt;语句也更新好了那么需要将更新的值提交啊，也就是需要提交本次的事务了，因为只要事务成功提交了，才会将最后的变更保存到数据库，在提交事务前仍然会具有相关的其他操作：将 redo Log Buffer 中的数据持久化到磁盘中，就是将 redo log buffer 中的数据写入到 redo log 磁盘文件中，一般情况下，redo log Buffer 数据写入磁盘的策略是立即刷入磁盘&lt;/p&gt;

&lt;h4 id=&quot;24-mysql更新数据的过程&quot;&gt;&lt;strong&gt;2.4 MYSQL更新数据的过程&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;截至目前，我们应该都熟悉了 MySQL 的执行器调用存储引擎是怎么将一条 SQL 加载到缓冲池和记录哪些日志的，流程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;准备更新一条 SQL 语句&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MySQL（innodb）会先去缓冲池（BufferPool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（BufferPool）中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在加载到 Buffer Pool 的同时，会将这条数据的原始记录保存到 undo 日志文件中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;innodb 会在 Buffer Pool 中执行更新操作&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;更新后的数据会记录在 redo log buffer 中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MySQL 提交事务的时候，会将 redo log buffer 中的数据写入到 redo 日志文件中 刷磁盘可以通过 innodb_flush_log_at_trx_commit 参数来设置&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;值为 0 表示不刷入磁盘&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;值为 1 表示立即刷入磁盘&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;值为 2 表示先刷到 os cache&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;myslq 重启的时候会将 redo 日志恢复到缓冲池中&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/63.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3总结&quot;&gt;&lt;strong&gt;3、总结：&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;我们再回顾下&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Buffer Pool 是 MySQL 的一个非常重要的组件，因为针对数据库的增删改操作都是在 Buffer Pool 中完成的&lt;/li&gt;
  &lt;li&gt;Undo log 记录的是数据操作前的样子&lt;/li&gt;
  &lt;li&gt;redo log 记录的是数据被操作后的样子（redo log 是 Innodb 存储引擎特有）&lt;/li&gt;
  &lt;li&gt;bin log 记录的是整个操作记录（这个对于主从复制具有非常重要的意义）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;具体更新一条记录 UPDATE t_user SET name = ‘xiaolin’ WHERE id = 1; 的流程如下:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；&lt;/li&gt;
  &lt;li&gt;如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;如果一样的话就不进行后续更新流程；&lt;/li&gt;
  &lt;li&gt;如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。&lt;/li&gt;
  &lt;li&gt;InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 &lt;strong&gt;WAL 技术&lt;/strong&gt;，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。&lt;/li&gt;
  &lt;li&gt;至此，一条记录更新完了。&lt;/li&gt;
  &lt;li&gt;在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。&lt;/li&gt;
  &lt;li&gt;事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）：&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；&lt;/li&gt;
  &lt;li&gt;commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;至此，一条更新语句执行完成。&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Ted</name></author><category term="数据库" /><summary type="html">1、概念</summary></entry><entry><title type="html">Garbage Collection</title><link href="http://www.helloted.com/golang/2022/12/01/gc/" rel="alternate" type="text/html" title="Garbage Collection" /><published>2022-12-01T20:00:00+08:00</published><updated>2022-12-01T20:00:00+08:00</updated><id>http://www.helloted.com/golang/2022/12/01/gc</id><content type="html" xml:base="http://www.helloted.com/golang/2022/12/01/gc/">&lt;h3 id=&quot;一定义&quot;&gt;&lt;strong&gt;一、定义&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;GC，全称 Garbage Collection，即垃圾回收，是一种自动内存管理的机制。&lt;/p&gt;

&lt;p&gt;当程序向操作系统申请的内存不再需要时，垃圾回收主动将其回收并供其他代码进行内存申请时候复用，或者将其归还给操作系统，这种针对内存级别资源的自动回收过程，即为垃圾回收。&lt;/p&gt;

&lt;p&gt;而负责垃圾回收的程序组件，即为垃圾回收器。&lt;/p&gt;

&lt;p&gt;垃圾回收其实一个完美的 “Simplicity is Complicated” 的例子：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一方面，程序员受益于 GC，无需操心、也不再需要对内存进行手动的申请和释放操作，GC 在程序运行时自动释放残留的内存。也能够消除一些需要手动管理内存才会出现的运行时错误：
    &lt;ul&gt;
      &lt;li&gt;在仍然有指向内存区块的指针的情况下释放这块内存时，会产生悬挂指针，从而后续可能错误的访问已经用于他用的内存区域。&lt;/li&gt;
      &lt;li&gt;多重释放同一块申请的内存区域可能导致不可知的内存损坏&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;另一方面，GC 对程序员几乎不可见，仅在程序需要进行特殊优化时，通过提供可调控的 API，对 GC 的运行时机、运行开销进行把控的时候才得以现身。这也就造就了没有 GC 的一些优势：&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;没有额外的性能开销&lt;/li&gt;
  &lt;li&gt;精准的手动内存管理，极致的利用机器的性能&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二gc的语言&quot;&gt;&lt;strong&gt;二、GC的语言&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;从原理上而言，所有的语言都能够自行实现 GC。&lt;/p&gt;

&lt;p&gt;从语言诞生之初就提供 GC 的语言，例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Python&lt;/li&gt;
  &lt;li&gt;JavaScript&lt;/li&gt;
  &lt;li&gt;Java&lt;/li&gt;
  &lt;li&gt;Objective-C&lt;/li&gt;
  &lt;li&gt;Swift&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而不以 GC 为目标，被直接设计为手动管理内存、但可以自行实现 GC 的语言有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;C&lt;/li&gt;
  &lt;li&gt;C++&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;也有一些语言可以在编译期，依靠编译器插入清理代码的方式，实现精准的清理，例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Rust&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;三gc方式&quot;&gt;&lt;strong&gt;三、GC方式&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;所有的 GC 算法其存在形式可以归结为追踪（Tracing）和引用计数（Reference Counting）这两种形式的混合运用。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;追踪式 GC从根对象出发，根据对象之间的引用信息，一步步推进直到扫描完毕整个堆并确定需要保留的对象，从而回收所有可回收的对象。Go、 Java、V8 对 JavaScript 的实现等均为追踪式 GC。&lt;/li&gt;
  &lt;li&gt;引用计数式 GC每个对象自身包含一个被引用的计数器，当计数器归零时自动得到回收。因为此方法缺陷较多，在追求高性能时通常不被应用。Python、Objective-C 等均为引用计数式 GC。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前比较常见的 GC 实现方式包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;追踪式，分为多种不同类型，例如：
    &lt;ul&gt;
      &lt;li&gt;标记清扫：从根对象出发，将确定存活的对象进行标记，并清扫可以回收的对象。&lt;/li&gt;
      &lt;li&gt;标记整理：为了解决内存碎片问题而提出，在标记过程中，将对象尽可能整理到一块连续的内存上。&lt;/li&gt;
      &lt;li&gt;增量式：将标记与清扫的过程分批执行，每次执行很小的部分，从而增量的推进垃圾回收，达到近似实时、几乎无停顿的目的。&lt;/li&gt;
      &lt;li&gt;增量整理：在增量式的基础上，增加对对象的整理过程。&lt;/li&gt;
      &lt;li&gt;分代式：将对象根据存活时间的长短进行分类，存活时间小于某个值的为年轻代，存活时间大于某个值的为老年代，永远不会参与回收的对象为永久代。并根据分代假设（如果一个对象存活时间不长则倾向于被回收，如果一个对象已经存活很长时间则倾向于存活更长时间）对对象进行回收。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;引用计数：根据对象自身的引用计数来回收，当引用计数归零时立即回收。&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ted</name></author><category term="Golang" /><summary type="html">一、定义</summary></entry><entry><title type="html">操作系统内存管理</title><link href="http://www.helloted.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2022/11/25/mem/" rel="alternate" type="text/html" title="操作系统内存管理" /><published>2022-11-25T20:00:00+08:00</published><updated>2022-11-25T20:00:00+08:00</updated><id>http://www.helloted.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2022/11/25/mem</id><content type="html" xml:base="http://www.helloted.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2022/11/25/mem/">&lt;h3 id=&quot;一内存管理&quot;&gt;一、内存管理&lt;/h3&gt;

&lt;p&gt;操作系统的内存管理非常重要，主要负责下面这些事情：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;内存的分配与回收：对进程所需的内存进行分配和释放，malloc 函数：申请内存，free 函数：释放内存。&lt;/li&gt;
  &lt;li&gt;地址转换：将程序中的虚拟地址转换成内存中的物理地址。&lt;/li&gt;
  &lt;li&gt;内存扩充：当系统没有足够的内存时，利用虚拟内存技术或自动覆盖技术，从逻辑上扩充内存。&lt;/li&gt;
  &lt;li&gt;内存映射：将一个文件直接映射到进程的进程空间中，这样可以通过内存指针用读写内存的办法直接存取文件内容，速度更快。&lt;/li&gt;
  &lt;li&gt;内存优化：通过调整内存分配策略和回收算法来优化内存使用效率。&lt;/li&gt;
  &lt;li&gt;内存安全：保证进程之间使用内存互不干扰，避免一些恶意程序通过修改内存来破坏系统的安全性。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;11-malloc是如何分配内存的&quot;&gt;&lt;strong&gt;1.1 malloc是如何分配内存的？&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;malloc 是 C 语言标准库中用于动态内存分配的函数。它从堆（heap）上分配指定大小的内存块，并返回一个指向该内存块的指针。如果分配失败，它返回 NULL。&lt;/p&gt;

&lt;p&gt;基本工作原理&lt;/p&gt;

&lt;p&gt;在使用 malloc 进行内存分配时，实际的处理过程涉及两个层面：首先是从进程的内存池中尝试分配内存，如果进程的内存池中没有足够的空间满足当前的请求，那么 malloc 会从操作系统那里请求更多的内存。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从进程内存池中分配
    &lt;ul&gt;
      &lt;li&gt;内存池管理：进程的内存池通常由 malloc 管理，它包含了一系列已经从操作系统获取并为进程预留的内存块。这些内存块可能是连续的或者是非连续的，取决于之前的分配和释放操作。&lt;/li&gt;
      &lt;li&gt;内存分配尝试：当调用 malloc 请求内存时，malloc 首先检查其管理的内存池中是否有足够的空闲内存来满足请求。这涉及到查找合适大小的空闲块，可能需要根据内存分配算法（如首次适应、最佳适应等）来选择。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;从操作系统请求内存
    &lt;ul&gt;
      &lt;li&gt;内存池不足：如果进程的内存池中没有足够的空闲内存块来满足当前的请求，malloc 需要从操作系统请求更多的内存。&lt;/li&gt;
      &lt;li&gt;系统调用：malloc 通过系统调用（如 sbrk 或 mmap）向操作系统请求额外的内存。这些调用会将更多的内存区域分配给进程，从而扩展进程的堆空间。内存整合和返回&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;内存整合：获取到新的内存后，malloc 可能会执行一些内存整合操作，如合并相邻的空闲块，以优化内存的使用和减少碎片。&lt;/li&gt;
  &lt;li&gt;返回内存指针：完成内存分配后，malloc 将返回一个指向新分配内存块的指针。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要注意的是，malloc函数只负责分配内存，并不会初始化内存块的内容。如果需要初始化内存块，可以使用memset等函数进行操作。&lt;/p&gt;

&lt;h4 id=&quot;12-内存碎片&quot;&gt;1.2 &lt;strong&gt;内存碎片&lt;/strong&gt;&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;内部内存碎片(Internal Memory Fragmentation，简称为内存碎片)：已经分配给进程使用但未被使用的内存。导致内部内存碎片的主要原因是，当采用固定比例比如 2 的幂次方进行内存分配时，进程所分配的内存可能会比其实际所需要的大。举个例子，一个进程只需要 65 字节的内存，但为其分配了 128（2^7） 大小的内存，那 63 字节的内存就成为了内部内存碎片。&lt;/li&gt;
  &lt;li&gt;外部内存碎片(External Memory Fragmentation，简称为外部碎片)：由于未分配的连续内存区域太小，以至于不能满足任意进程所需要的内存分配请求，这些小片段且不连续的内存空间被称为外部碎片。也就是说，外部内存碎片指的是那些并未分配给进程但又不能使用的内存。我们后面介绍的分段机制就会导致外部内存碎片。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二虚拟内存&quot;&gt;二、虚拟内存&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;虚拟内存(Virtual Memory)&lt;/strong&gt; 是计算机系统内存管理非常重要的一个技术，本质上来说它只是逻辑存在的，是一个假想出来的内存空间，主要作用是作为进程访问主存（物理内存）的桥梁并简化内存管理。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/60.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;虚拟地址空间构成虚拟内存。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片。还有部分暂时存储在外部磁盘存储器上（Swap），在需要时进行数据交换。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;虚拟内存提供了以下能力&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;隔离进程：物理内存通过虚拟地址空间访问，虚拟地址空间与进程一一对应。每个进程都认为自己拥有了整个物理内存，进程之间彼此隔离，一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。&lt;/li&gt;
  &lt;li&gt;提升物理内存利用率：有了虚拟地址空间后，操作系统只需要将进程当前正在使用的部分数据或指令加载入物理内存。&lt;/li&gt;
  &lt;li&gt;简化内存管理：进程都有一个一致且私有的虚拟地址空间，程序员不用和真正的物理内存打交道，而是借助虚拟地址空间访问物理内存，从而简化了内存管理。&lt;/li&gt;
  &lt;li&gt;多个进程共享物理内存：进程在运行过程中，会加载许多操作系统的动态库。这些库对于每个进程而言都是公用的，它们在内存中实际只会加载一份，这部分称为共享内存。&lt;/li&gt;
  &lt;li&gt;提高内存使用安全性：控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性。&lt;/li&gt;
  &lt;li&gt;提供更大的可使用内存空间：可以让程序拥有超过系统物理内存大小的可用内存空间。这是因为当物理内存不够用时，可以利用磁盘充当，将物理内存页（通常大小为 4 KB）保存到磁盘文件（会影响读写速度），数据或代码页会根据需要在物理内存与磁盘之间移动。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;总的来说，虚拟内存技术通过将物理内存和磁盘空间结合起来，为每个进程提供了一个连续的、抽象的地址空间。它扩展了地址空间、提供了内存管理和保护机制，支持共享和隔离，提高了系统的性能和资源利用率，使得计算机系统更加灵活、稳定和安全。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;虚拟内存的工作原理如下&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;地址空间划分：每个进程都有自己的虚拟地址空间，通常是一个连续的地址范围。这个地址空间被划分为多个固定大小的页面（通常是4KB），每个页面都有一个唯一的虚拟地址。&lt;/li&gt;
  &lt;li&gt;页面映射：虚拟内存管理器将虚拟页面映射到物理内存或磁盘上的页面框（通常也是4KB）。这个映射关系存储在页表中，页表记录了虚拟页面和物理页面之间的对应关系。&lt;/li&gt;
  &lt;li&gt;页面置换：当进程访问一个虚拟页面时，虚拟内存管理器首先检查该页面是否已经在物理内存中。如果在物理内存中，就直接访问；如果不在物理内存中，就发生了缺页中断。&lt;/li&gt;
  &lt;li&gt;缺页中断处理：当发生缺页中断时，操作系统会根据页表中的映射关系，将对应的页面从磁盘读取到物理内存中的一个空闲页面框中，并更新页表。然后，进程的执行可以继续，就好像该页面一直在物理内存中一样。&lt;/li&gt;
  &lt;li&gt;页面置换算法：当物理内存不足时，操作系统需要选择一个页面进行置换，将其写回磁盘并释放其物理内存。常用的页面置换算法有最近最久未使用（LRU）、先进先出（FIFO）和时钟（Clock）算法等。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;虚拟内存缺点&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;性能开销：虚拟内存的使用涉及到页表查找和磁盘I/O操作，这些都可能导致性能下降。特别是当系统频繁进行换页操作时，会显著影响系统性能，这种现象称为“抖动”。&lt;/li&gt;
  &lt;li&gt;硬盘速度限制：虽然现代固态硬盘（SSD）的速度已经大幅提升，但相比于物理内存，硬盘的访问速度仍然较慢。频繁的访问硬盘来加载或存储页面会减慢程序的执行速度。&lt;/li&gt;
  &lt;li&gt;复杂的内存管理：虚拟内存系统需要复杂的硬件支持（如内存管理单元MMU）和操作系统级的支持，这增加了系统设计和维护的复杂性。&lt;/li&gt;
  &lt;li&gt;资源消耗：维护页表和相关数据结构需要额外的内存和CPU资源。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;三虚拟内存实现的三种机制&quot;&gt;三、虚拟内存实现的三种机制&lt;/h3&gt;

&lt;p&gt;虚拟内存（Virtual Memory）是一种计算机系统技术，它使得程序可以使用比实际物理内存更大的地址空间。虚拟内存通过将虚拟地址映射到物理地址，实现了内存的高效管理和保护。虚拟内存的实现主要有三种机制：分页（Paging）、分段（Segmentation）和段页结合（Segmentation with Paging）。&lt;/p&gt;

&lt;h4 id=&quot;1-分页机制paging&quot;&gt;1. 分页机制（Paging）&lt;/h4&gt;

&lt;p&gt;分页机制是虚拟内存实现中最常见的一种方式。它将虚拟地址空间和物理地址空间都划分为固定大小的块，分别称为页（Page）和页框（Frame）。虚拟地址由页号和页内偏移量组成，通过页表（Page Table）将页号映射到物理内存中的页框。&lt;/p&gt;

&lt;h5 id=&quot;特点&quot;&gt;特点&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;固定大小&lt;/strong&gt;：页和页框大小固定，简化了内存管理。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;减少外部碎片&lt;/strong&gt;：由于页大小固定，减少了外部碎片。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;内存保护&lt;/strong&gt;：每个页可以有不同的访问权限。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-分段机制segmentation&quot;&gt;2. 分段机制（Segmentation）&lt;/h4&gt;

&lt;p&gt;分段机制将虚拟地址空间划分为若干段，每个段有一个段基址和段长度。虚拟地址由段选择子和段内偏移量组成。段选择子用于选择段，段内偏移量用于指定段内的具体地址。&lt;/p&gt;

&lt;h5 id=&quot;特点-1&quot;&gt;特点&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt;：可以根据需要动态调整段的大小。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;保护性&lt;/strong&gt;：每个段可以有不同的访问权限，提供了内存保护。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;共享性&lt;/strong&gt;：多个进程可以共享同一个段。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3-段页结合机制segmentation-with-paging&quot;&gt;3. 段页结合机制（Segmentation with Paging）&lt;/h4&gt;

&lt;p&gt;段页结合机制结合了分段和分页的优点。内存首先被划分为段，每个段再划分为若干页。虚拟地址由段选择子、页号和页内偏移量组成。&lt;/p&gt;

&lt;h5 id=&quot;特点-2&quot;&gt;特点&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;灵活性和固定大小结合&lt;/strong&gt;：段提供灵活性，页提供固定大小的管理。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;减少外部碎片&lt;/strong&gt;：分页减少了外部碎片。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;内存保护和共享&lt;/strong&gt;：段和页都可以有不同的访问权限，提供了更细粒度的内存保护和共享。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;总结&quot;&gt;总结&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;分段机制（Segmentation）：分段机制将虚拟地址空间划分为多个段（segment），每个段具有不同的大小和属性。每个段都有一个基地址和长度，通过将段内的偏移量与基地址相加，可以得到物理地址。分段机制可以提供灵活的地址空间管理，但可能会导致外部碎片问题。&lt;/li&gt;
  &lt;li&gt;分页机制（Paging）：分页机制将虚拟地址空间和物理内存空间划分为固定大小的页（page），通常为4KB或者更大。虚拟地址被划分为页号和页内偏移量，通过页表（Page Table）来映射虚拟页号到物理页框号。分页机制可以提供更好的内存利用率和地址空间的连续性，但可能会导致内部碎片问题。&lt;/li&gt;
  &lt;li&gt;段页机制（Segmentation with Paging）：段页机制是分段机制和分页机制的结合，它将虚拟地址空间划分为多个段，每个段再划分为多个页。通过段表（Segment Table）和页表的组合，可以将虚拟地址映射到物理地址。段页机制综合了分段和分页的优点，提供了更灵活的地址空间管理和更好的内存利用率。&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ted</name></author><category term="操作系统" /><summary type="html">一、内存管理</summary></entry><entry><title type="html">Elasticsearch</title><link href="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/20/es/" rel="alternate" type="text/html" title="Elasticsearch" /><published>2022-11-20T20:00:00+08:00</published><updated>2022-11-20T20:00:00+08:00</updated><id>http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/20/es</id><content type="html" xml:base="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/20/es/">&lt;h3 id=&quot;1简介&quot;&gt;&lt;strong&gt;1、简介&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Elasticsearch是一个开源的分布式搜索和分析引擎，构建在Apache Lucene库之上。它提供了一个高性能、可扩展和全文搜索的解决方案，适用于各种应用场景。&lt;/p&gt;

&lt;p&gt;以下是一些关键特性和功能：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;分布式架构：Elasticsearch是一个分布式数据库，可以在多个节点上分布和复制数据，提供高可用性和容错性。它使用自动分片和复制机制来实现数据的分布和冗余存储。&lt;/li&gt;
  &lt;li&gt;实时搜索和分析：Elasticsearch以其快速的搜索性能和实时数据处理能力而闻名。它能够在大规模数据集上进行快速的全文搜索、过滤和聚合操作，并支持复杂的查询和实时数据分析。&lt;/li&gt;
  &lt;li&gt;强大的查询语言：Elasticsearch使用基于Lucene查询语法的查询语言，支持丰富的搜索和过滤功能。它提供了诸如全文搜索、模糊搜索、范围搜索、布尔搜索、聚合等功能，使用户能够灵活地构建复杂的查询。&lt;/li&gt;
  &lt;li&gt;多种数据类型支持：Elasticsearch支持多种数据类型的索引和查询，包括文本、数字、日期、地理空间等。它提供了丰富的分析和处理工具，用于处理不同类型的数据。&lt;/li&gt;
  &lt;li&gt;可扩展性和高性能：Elasticsearch具有良好的可扩展性，可以水平扩展以处理大量数据和高并发查询。它能够快速地索引和搜索大规模数据集，并提供低延迟的响应时间。&lt;/li&gt;
  &lt;li&gt;数据安全和权限控制：Elasticsearch提供了安全性和权限控制机制，可以对数据进行访问控制和身份验证。它支持基于角色的访问控制和SSL/TLS加密，以保护数据的安全性。&lt;/li&gt;
  &lt;li&gt;生态系统和集成：Elasticsearch拥有丰富的生态系统，包括Kibana（数据可视化工具）、Logstash（日志收集和处理工具）、Beats（轻量级数据采集器）等。这些工具可以与Elasticsearch无缝集成，提供全面的数据处理和可视化能力。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Elasticsearch的灵活性和功能丰富性使其成为处理大规模数据、实时搜索和分析的理想选择。它被广泛应用于日志分析、企业搜索、电商平台、实时监控、地理空间分析等各种领域和应用场景。&lt;/p&gt;

&lt;h3 id=&quot;2应用场景&quot;&gt;&lt;strong&gt;2、应用场景&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Elasticsearch是一个功能强大的分布式搜索和分析引擎，适用于许多不同的应用场景。以下是一些常见的Elasticsearch应用场景：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;实时日志分析：Elasticsearch能够高效地处理大量的实时日志数据，并提供强大的搜索和聚合功能，使得日志分析和监控变得更加容易和高效。&lt;/li&gt;
  &lt;li&gt;全文搜索引擎：Elasticsearch以其快速的搜索性能和高级的文本分析功能而闻名，适用于构建全文搜索引擎、内容管理系统、电子商务平台等需要强大搜索能力的应用。&lt;/li&gt;
  &lt;li&gt;企业搜索和知识管理：Elasticsearch可以帮助组织构建内部搜索引擎，用于快速检索和浏览企业内部的文档、知识库、文档存档等。&lt;/li&gt;
  &lt;li&gt;实时数据分析和可视化：Elasticsearch与Kibana（一个数据可视化工具）结合使用，可以实现实时数据的分析和可视化，帮助用户更好地理解和利用数据。&lt;/li&gt;
  &lt;li&gt;产品目录和电商搜索：Elasticsearch提供了强大的搜索和过滤功能，适用于构建产品目录、电商平台等需要快速搜索和过滤商品的应用。&lt;/li&gt;
  &lt;li&gt;地理空间数据分析：Elasticsearch支持地理空间数据的索引和查询，适用于构建位置服务、地理信息系统（GIS）等应用。&lt;/li&gt;
  &lt;li&gt;实时监控和告警：Elasticsearch可以用于实时监控和告警系统，通过收集和分析实时数据，及时发现和处理异常情况。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这只是一些常见的应用场景，实际上，Elasticsearch的灵活性和可扩展性使其适用于许多其他领域和用途。它的强大搜索和分析功能以及分布式架构使其成为处理大规模数据和实时数据的理想选择。&lt;/p&gt;

&lt;h3 id=&quot;3对比&quot;&gt;&lt;strong&gt;3、对比&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;当涉及到Elasticsearch和MySQL这两个数据库时，以下是它们之间的一些详细对比：&lt;/p&gt;

&lt;p&gt;数据存储和查询语言：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MySQL是一种关系型数据库管理系统（RDBMS），使用表格结构来存储数据，并使用结构化查询语言（SQL）作为主要的查询语言。&lt;/li&gt;
  &lt;li&gt;Elasticsearch是一个分布式文档存储数据库，使用无模式的JSON文档来存储数据，并使用自己的查询语言（基于Lucene查询语法）进行搜索和分析。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;数据模型和灵活性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MySQL使用固定的表格结构，需要在创建表时定义列和数据类型。它适用于结构化数据和事务处理。&lt;/li&gt;
  &lt;li&gt;Elasticsearch使用动态映射，可以根据数据自动创建索引和字段。它适用于非结构化和半结构化数据，具有更大的灵活性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;搜索和分析能力：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MySQL提供基本的全文搜索和模糊搜索功能，但它的搜索能力相对较弱。它更适合于简单的关系型查询。&lt;/li&gt;
  &lt;li&gt;Elasticsearch以其强大的全文搜索、过滤和聚合功能而闻名，适用于构建全文搜索引擎、实时数据分析和复杂的搜索场景。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;分布式架构和可扩展性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MySQL可以进行主从复制和分片，但其分布式能力相对较弱。它更适合于单机或小规模的应用。&lt;/li&gt;
  &lt;li&gt;Elasticsearch是一个分布式数据库，具有自动分片和复制机制，可以在多个节点上分布和复制数据，提供高可用性和容错性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;数据处理和性能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MySQL适用于事务处理和关系型数据的存储，强调数据一致性和事务支持。&lt;/li&gt;
  &lt;li&gt;Elasticsearch适用于大规模数据的搜索、分析和实时数据处理，具有高度可扩展性和分布式计算能力。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;数据安全和权限控制：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MySQL提供了丰富的安全性和权限控制机制，包括用户认证、访问控制和数据加密等功能。&lt;/li&gt;
  &lt;li&gt;Elasticsearch也提供了安全性和权限控制机制，可以对数据进行访问控制和身份验证。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;综上所述，MySQL适用于传统的关系型数据存储和事务处理，而Elasticsearch适用于大规模数据的搜索、分析和实时数据处理。选择哪种数据库取决于具体的需求和应用场景。在某些情况下，两者也可以结合使用，以发挥各自的优势。&lt;/p&gt;</content><author><name>Ted</name></author><category term="数据库" /><summary type="html">1、简介</summary></entry><entry><title type="html">数据库事务之锁类型</title><link href="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/12/lock/" rel="alternate" type="text/html" title="数据库事务之锁类型" /><published>2022-11-12T20:00:00+08:00</published><updated>2022-11-12T20:00:00+08:00</updated><id>http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/12/lock</id><content type="html" xml:base="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/12/lock/">&lt;p&gt;&lt;img src=&quot;/img/Simple_2/54.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1乐观锁和悲观锁&quot;&gt;1、乐观锁和悲观锁&lt;/h3&gt;

&lt;p&gt;乐观锁和悲观锁是按照对并发冲突的处理方式进行分类的。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;乐观锁：乐观锁实际上就是没锁，认为对同一数据的并发操作不会总发生，属于小概率事件，不用每次都对数据上锁，也就是不采用数据库自身的锁机制，而是通过程序来实现。在程序上，我们可以采用版本号机制或者时间戳机制实现。你能看到乐观锁就是程序员自己控制数据并发操作的权限，基本是通过给数据行增加一个戳（版本号或者时间戳），从而证明当前拿到的数据是否最新&lt;/li&gt;
  &lt;li&gt;悲观锁：悲观锁假设并发冲突的概率较高，因此在读取数据时会立即加锁，阻止其他事务对数据进行读取或修改。悲观锁通过共享锁或排他锁来实现对数据的锁定。
    &lt;ul&gt;
      &lt;li&gt;共享锁允许多个事务同时读取数据，但不允许修改；&lt;/li&gt;
      &lt;li&gt;排他锁则只允许一个事务对数据进行读取或修改。悲观锁适用于并发修改较多、冲突较多的场景。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以二者区别是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;乐观锁在读取时不加锁，而是在提交时检查冲突。&lt;/li&gt;
  &lt;li&gt;悲观锁在读取时立即加锁，以防止其他事务对数据进行修改。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;举例&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;有商品表item，需要对库存quantity进行更新。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;乐观锁&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;整个过程中没有加锁&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;查询出商品库存信息，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quantity&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;修改商品库存为&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，在提交修改时，进行校验和冲突处理，整个过程中没有加锁&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;update&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quantity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quantity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;或者，借助一个&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;Version&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;字段&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;查询出商品信息，&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;修改商品库存为&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，并且将&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;update&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quantity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;悲观锁&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;则我们在读取时立即加锁锁定，然后再进行修改&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;开始事务&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;读取加锁&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;这里加的是排它锁&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quantity&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;修改库存&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;update&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quantity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;提交事务&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;commit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;悲观锁补充：&lt;/strong&gt;
悲观锁的实现，往往依靠数据库提供的锁机制。在数据库中，悲观锁的流程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在对记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。&lt;/li&gt;
  &lt;li&gt;如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。具体响应方式由开发者根据实际需要决定。&lt;/li&gt;
  &lt;li&gt;如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。&lt;/li&gt;
  &lt;li&gt;其间如果有其他事务对该记录做加锁的操作，都要等待当前事务解锁或直接抛出异常。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，还会降低并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数据。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;问：如何处理死锁&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;策略一：直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置；默认为 50s，即如果不开启死锁检测，则在发生死锁之后，会等待 50s 后回滚事务释放锁。&lt;/li&gt;
  &lt;li&gt;策略二：发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。innodb 默认开启死锁检测，但是死锁检测会消耗大量的CPU资源。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2共享锁和排它锁&quot;&gt;2、共享锁和排它锁&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;共享锁(Shared Lock)，又称之为读锁，简称S锁
    &lt;ul&gt;
      &lt;li&gt;当事务对数据加上读锁后，其他事务只能对该数据加读锁，不能做任何修改操作，也就是不能添加写锁。共享锁主要是为了支持并发的读取数据而出现的，读取数据时，不允许其他事务对当前数据进行修改操作，从而避免”不可重读”的问题的出现。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;排它锁(Exclusive Lock)，又称之为写锁，简称X锁
    &lt;ul&gt;
      &lt;li&gt;当事务对数据加上写锁后，其他事务既不能对该数据添加读写，也不能对该数据添加写锁，写锁与其他锁都是互斥的。只有当前数据写锁被释放后，其他事务才能对其添加写锁或者是读锁。写锁主要是为了解决在修改数据时，不允许其他事务对当前数据进行修改和读取操作，达到了串行处理。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;区别：&lt;/p&gt;

&lt;p&gt;共享锁，多个事务共享读取，保证了本事务可以重复读。&lt;/p&gt;

&lt;p&gt;排它锁，就是串行处理，单个事务占有，其他事务不能读写。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;属性锁&lt;/th&gt;
      &lt;th&gt;共享锁（S）&lt;/th&gt;
      &lt;th&gt;排它锁（X）&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;共享锁（S）&lt;/td&gt;
      &lt;td&gt;允许&lt;/td&gt;
      &lt;td&gt;不允许&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;排它锁（X）&lt;/td&gt;
      &lt;td&gt;不允许&lt;/td&gt;
      &lt;td&gt;不允许&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;注：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;普通的 SELECT 语句在默认情况下不会获取共享锁。
    &lt;ul&gt;
      &lt;li&gt;普通的 SELECT 语句使用的是快照读，共享读锁（Shared Read Lock），而不是共享锁（Shared Lock）。共享读锁是一种特殊的共享锁，它允许多个事务同时读取相同的数据，只为本事务所用，但不会阻塞其他事务的共享读锁或排他写锁。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;加共享锁 lock in share mode ，加排他锁 for update&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lock&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;share&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;共享锁&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;排它锁&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3表级锁和行级锁&quot;&gt;&lt;strong&gt;3、表级锁和行级锁&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;表级锁（Table-level Lock）：对整个表进行锁定，阻止其他事务对表的读取或修改。&lt;/li&gt;
  &lt;li&gt;行级锁（Row-level Lock）：对表中的单个行记录进行锁定，允许其他事务对其他行进行读取或修改。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;举例&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;表级锁&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOCK&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TABLES&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;READ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;读取锁&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;共享锁&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOCK&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TABLES&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WRITE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;写入表锁&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;排它锁&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;UNLOCK&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TABLES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;行级锁&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;需要注意的是，表级锁在 MySQL 中一般用于特定的场景，如备份、导入导出数据等操作，而不是常规的并发控制手段。在大多数情况下，MySQL 更常用的是行级锁来实现并发控制。表级锁的使用需要谨慎，因为它会对整个表进行锁定，可能会导致其他事务的阻塞和性能问题&lt;/p&gt;

&lt;h3 id=&quot;4行级锁&quot;&gt;&lt;strong&gt;4、行级锁&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;按照锁的粒度和范围分类：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;记录锁（Record Lock）：对数据库中的单个记录(不是单行，可以多行)进行锁定，以防止其他事务对该记录进行&lt;strong&gt;修改&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;间隙锁（Gap Lock）：对索引范围内的间隙进行锁定，以防止其他事务在该范围内&lt;strong&gt;插入新记录&lt;/strong&gt;。临键锁还锁定了记录之间的间隙，以防止其他事务在这些间隙中插入新记录。这样可以保证在索引范围内的间隙中不会出现新的记录，从而维护了数据的完整性&lt;/li&gt;
  &lt;li&gt;临键锁（Next-Key Lock）：结合了记录锁和间隙锁的特性，既锁定了记录，也锁定了记录之间的间隙。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;记录锁和间隙锁的区别：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;记录锁只影响其他事务对同一记录的&lt;strong&gt;修改&lt;/strong&gt;操作，而间隙锁影响其他事务对索引范围内的&lt;strong&gt;插入&lt;/strong&gt;操作&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;怎么确定是什么锁&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;加锁的基本单位为next-key lock&lt;/p&gt;

&lt;p&gt;先定位到next-key lock，然后再看怎么退化，缩小范围&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;举例-记录锁&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;事务1：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;users&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 对记录进行修改操作&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COMMIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;事务2：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;users&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 尝试对同一记录进行修改操作，但会被阻塞等待事务1释放锁&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COMMIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在事务1中，通过 FOR UPDATE 语句获取了对 id 为 1 的记录的排它锁。这意味着其他事务无法同时对该记录进行修改，事务2在尝试获取同一记录的锁时会被阻塞，直到事务1释放锁。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;多行&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;users&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 对满足条件的记录进行修改操作&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COMMIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;间隙锁举例&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;事务1：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;users&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 对满足条件的记录进行修改操作&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COMMIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;事务2：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;users&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'John'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 尝试在事务1锁定的范围内插入新记录，但会被阻塞等待事务1释放锁&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COMMIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在事务1中，通过 FOR UPDATE 语句获取了满足条件 age &amp;gt; 30 AND age &amp;lt; 40 的记录范围的间隙锁。这意味着其他事务无法在该范围内插入新记录，事务2在尝试插入新记录时会被阻塞，直到事务1释放锁。&lt;/p&gt;</content><author><name>Ted</name></author><category term="数据库" /><summary type="html"></summary></entry><entry><title type="html">MongoDB</title><link href="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/12/mongo/" rel="alternate" type="text/html" title="MongoDB" /><published>2022-11-12T20:00:00+08:00</published><updated>2022-11-12T20:00:00+08:00</updated><id>http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/12/mongo</id><content type="html" xml:base="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/12/mongo/">&lt;h4 id=&quot;1mongodb简介&quot;&gt;&lt;strong&gt;1、MongoDB简介&lt;/strong&gt;&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;MongoDB是一个文档数据库(以 JSON 为数据模型)，此处文档指的是JSON Docunment，并非一般理解的PDF，WORD文档。&lt;/li&gt;
  &lt;li&gt;MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像 关系数据库的。&lt;/li&gt;
  &lt;li&gt;MongoDB支持的数据结构非常松散，数据格式是BSON，一种类似JSON的二进制形式的存储格 式，简称Binary JSON ，和JSON一样支持内嵌的文档对象和数组对象，因此可以存储比较复杂的数据类型。&lt;/li&gt;
  &lt;li&gt;MongoDB在数据库总排名第5，仅次于Oracle、MySQL等RDBMS，在NoSQL数据库排名首位。从诞生 以来，其项目应用广度、社区活跃指数持续上升。原则上 Oracle 和 MySQL 能做的事情，MongoDB 都能做(包括 ACID 事务)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;MongoDB 的三大核心特性是：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;No Schema&lt;/strong&gt;：MongoDB没有固定的Schema，少了很多约束条件，可以让数据的存储数据结构更灵活，存储速度更加快。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;高可用&lt;/strong&gt;：MongoDB能将数据分布在多台机器上实现冗余，同时检测主节点是否存活，当失活时能自动提升从节点为主节点，达到自动故障转移的目的。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分布式&lt;/strong&gt;（可平行扩展）：MongoDB使用分片技术对数据进行扩展，能自动分片、自动转移分片里面的数据块，让每一个服务器里面存储的数据都是一样大小。&lt;/li&gt;
  &lt;li&gt;MongoDB 还支持数据压缩、二级索引、全文搜索、地理分布等一系列的强大功能。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;MongoDB使用场景类型总结&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;读写分离应用&lt;/li&gt;
  &lt;li&gt;灵活多变的业务场景，MongoDB采用No-Schema的方式，免去表结构变更的痛苦，非常适用于初创型的业务需求。可以将模式固定的结构化数据存储在mysql中，模式灵活的业务存储在MongoDB中，高热数据存储在Redis或Memcache中，实现对业务数据高效存取，降低存储数据的投入成本。&lt;/li&gt;
  &lt;li&gt;移动应用，MongoDB支持二维空间索引，可以很好地支撑基于位置查询的移动类App的业务需求。同时MongoDB动态模式存储方式也非常适合存储多重系统的异构数据，满足移动App应用的需求。&lt;/li&gt;
  &lt;li&gt;物联网应用，MongoDB具有高性能和异步数据写入功能，特定场景下可达到内存数据库的处理能力。同时，库MongoDB中的分片集群实例，可按需配置Mongos和Shard组件的配置和个数，性能及存储空间可实现无限扩展，非常适合物联网高并发写入的场景。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;MongoDB提供二级索引功能满足动态查询的需求，利用MongoDB的map-reduce聚合框架进行多维度的数据分析。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;mysql与mongodb&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在处理大量数据方面，MongoDB 比 MySQL 更胜一筹；在云计算服务和需求频繁变化的项目上，MongoDB 也更具优势。&lt;/p&gt;

&lt;p&gt;MySQL数据结构和模式是固定的，因此保证了数据一致性和可靠性。MySQL还有一个好处，就是由于它支持基于 ACID 准则的事务操作，数据安全性更高。所以对于看重这些因素的项目来说，MySQL 是最合适的。&lt;/p&gt;

&lt;h3 id=&quot;2应用场景&quot;&gt;&lt;strong&gt;2、应用场景：&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;应用服务器的日志记录，日常我们会把一些应用日志存储到文本格式的文件中，这样不便于查看同时也不便于统计等。通过MongoDB存储，既可以很好的存储、统计同时也方便不同的业务场景下日志数据格式不一致等情况。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;第三方信息的抓取与存储，我们在一些业务场景中难免会去使用到第三方的数据，当接入多个第三方平台时，这时候我们需要考虑到每个平台数据格式不一致，自身的存储系统结构设计等情况。这时候我们使用MongoDB来存储就很好的避免了这个问题。&lt;/li&gt;
  &lt;li&gt;运维监控系统，在一些大型的项目中，监控是必不可少的。监控系统要监控的内容，可能是随时多变的，这时候使用MongoDB就体现了很大的便利。不需要去修改数据库的结构，直接根据业务需要灵活调整即可。大大降低了开发成本。&lt;/li&gt;
  &lt;li&gt;O2O业务场景，将送快递骑手、快递商家的信息（包含位置信息）存储在 MongoDB，然后通过 MongoDB 的地理位置查询，这样很方便的实现了查找附近的商家、骑手等功能。&lt;/li&gt;
  &lt;li&gt;游戏业务场景，使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，方便查询、更新。&lt;/li&gt;
  &lt;li&gt;社交业务场景，使用 MongoDB 存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引实现附近的人、地点等功能。&lt;/li&gt;
  &lt;li&gt;物联网业务场景，使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这些信息进行多维度的分析。&lt;/li&gt;
  &lt;li&gt;视频直播业务场景，视频直播，使用 MongoDB 存储用户信息、礼物信息等。&lt;/li&gt;
  &lt;li&gt;大数据应用，使用云数据库MongoDB作为大数据的云存储系统，随时进行数据提取分析，掌握行业动态。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;MongoDB提供二级索引功能满足动态查询的需求，利用MongoDB的map-reduce聚合框架进行多维度的数据分析。&lt;/p&gt;

&lt;p&gt;到底该不该使用MongoDB，下面的几道选择题可以辅助决策（来自MongoDB 公司的技术分享）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/55.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果上述有1个 Yes，可以考虑 MongoDB，2个及以上的 Yes，选择MongoDB绝不会后悔。&lt;/p&gt;

&lt;p&gt;当然，MongoDB也有自身的局限性，以下是MongoDB不适用的场景：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/56.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3mongodb的简单案例&quot;&gt;&lt;strong&gt;3、MongoDB的简单案例&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;从底层存储来讲，每个 Document 都是一个类 JSON 结构的 BSON（Binary JSON)。&lt;/p&gt;

&lt;p&gt;BSON是MongoDB首创的一种二进制存储格式，数据组织和访问方式完全和 JSON 一样。支持动态的添加字段、支持内嵌对象和数组对象。同时它也对 JSON 做了一些扩充，如支持 Date 和 BinData 数据类型。&lt;/p&gt;

&lt;p&gt;比如&lt;strong&gt;插入&lt;/strong&gt;文档的操作：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mysql&quot;&gt;db.book.insert(
{
  title: &quot;My first blog post&quot;,
  published: new Date(),
  tags: [ &quot;NoSQL&quot;, &quot;MongoDB&quot; ],
  type: &quot;Work&quot;,
  author : &quot;James&quot;,
  viewCount: 25,
  commentCount: 2
}
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行文档&lt;strong&gt;查找&lt;/strong&gt;：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; db.book.find({author : &quot;James&quot;})           
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;更新&lt;/strong&gt;文档的命令：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;db.book.update(
   {&quot;_id&quot; : ObjectId(&quot;5c61301c15338f68639e6802&quot;)},
   {&quot;$inc&quot;: {&quot;viewCount&quot;: 3} }
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;删除&lt;/strong&gt;文档的命令：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;db.book.remove({&quot;_id&quot;:ObjectId(&quot;5c612b2f15338f68639e67d5&quot;)})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在传统的SQL语法中，可以限定返回的字段，MongoDB可以使用Projection来表示：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;db.book.find({&quot;author&quot;: &quot;James&quot;},{&quot;_id&quot;: 1, &quot;title&quot;: 1, &quot;author&quot;: 1})         
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;实现简单的分页查询：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; db.book.find({}).sort({&quot;viewCount&quot; : -1}).skip(10).limit(5)       
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这种基于BSON/JSON 的语法格式并不复杂，它的表达能力或许要比SQL更加强大。与 MongoDB 做法类似的还有 ElasticSearch，后者是搜索数据库的佼佼者。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4、MongoDB和关系型数据库&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;MongoDB 在概念模型上参考了 SQL数据库，但并非完全相同。关于这点，也有人说，&lt;strong&gt;MongoDB 是 NoSQL中最像SQL的数据库&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在传统的关系型数据库中，存储方式是以表的形式存放，而在MongoDB中，以文档的形式存在。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/57.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MongoDB与关系型数据库的模型对应关系如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/58.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MongoDB概念与关系型数据库(RDBMS)非常类似:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/59.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据库(database):最外层的概念，可以理解为逻辑上的名称空间，一个数据库包含多个不同名称的集合。&lt;/li&gt;
  &lt;li&gt;集合(collection):相当于SQL中的表，一个集合可以存放多个不同的文档。&lt;/li&gt;
  &lt;li&gt;文档(document):一个文档相当于数据表中的一行，由多个不同的字段组成。&lt;/li&gt;
  &lt;li&gt;字段(field):文档中的一个属性，等同于列(column)。&lt;/li&gt;
  &lt;li&gt;索引(index):独立的检索式数据结构，与SQL概念一致。&lt;/li&gt;
  &lt;li&gt;id:每个文档中都拥有一个唯一的id字段，相当于SQL中的主键(primary key)。&lt;/li&gt;
  &lt;li&gt;视图(view):可以看作一种虚拟的(非真实存在的)集合，与SQL中的视图类似。从MongoDB 3.4版本开始提供了视图功能，其通过聚合管道技术实现。&lt;/li&gt;
  &lt;li&gt;聚合操作($lookup):MongoDB用于实现“类似”表连接(tablejoin)的聚合操作符。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;尽管这些概念大多与SQL标准定义类似，但MongoDB与传统RDBMS仍然存在不少差异，包括:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;半结构化，在一个集合中，文档所拥有的字段并不需要是相同的，而且也不需要对所用的字段进行 声明。因此，MongoDB具有很明显的半结构化特点。除了松散的表结构，文档还可以支持多级的 嵌套、数组等灵活的数据类型，非常契合面向对象的编程模型。&lt;/li&gt;
  &lt;li&gt;弱关系，MongoDB没有外键的约束，也没有非常强大的表连接能力。类似的功能需要使用聚合管 道技术来弥补。&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ted</name></author><category term="数据库" /><summary type="html">1、MongoDB简介</summary></entry><entry><title type="html">数据库事务之MVCC机制</title><link href="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/10/mvvc/" rel="alternate" type="text/html" title="数据库事务之MVCC机制" /><published>2022-11-10T20:00:00+08:00</published><updated>2022-11-10T20:00:00+08:00</updated><id>http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/10/mvvc</id><content type="html" xml:base="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/10/mvvc/">&lt;h4 id=&quot;1并发事务的四种场景&quot;&gt;&lt;strong&gt;1、并发事务的四种场景&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;并发事务中又会分为四种情况，分别是读-读、写-写、读-写、写-读，这四种情况分别对应并发事务执行时的四种场景。&lt;/p&gt;

&lt;h5 id=&quot;11读-读场景&quot;&gt;1.1、读-读场景&lt;/h5&gt;

&lt;p&gt;读-读场景即是指多个事务/线程在一起读取一个相同的数据，比如事务T1正在读取ID=88的行记录，事务T2也在读取这条记录，两个事务之间是并发执行的。读-读场景不存在任何数据竞争问题，不需要并发控制。&lt;/p&gt;

&lt;h5 id=&quot;12写-写场景&quot;&gt;1.2、写-写场景&lt;/h5&gt;

&lt;p&gt;写-写场景也比较简单，也就是指多个事务之间一起对同一数据进行写操作，比如事务T1对ID=88的行记录做修改操作，事务T2则对这条数据做删除操作，事务T1提交事务后想查询看一下，结果连这条数据都不见了，这也是所谓的脏写问题，也被称为更新覆盖问题，对于这个问题在所有数据库、所有隔离级别中都是零容忍的存在，最低的隔离级别也要解决这个问题。&lt;/p&gt;

&lt;h5 id=&quot;13读-写写-读场景&quot;&gt;1.3、读-写、写-读场景&lt;/h5&gt;

&lt;p&gt;读-写、写-读实际上从宏观角度来看，可以理解成同一种类型的操作，但从微观角度而言则是两种不同的情况，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;读-写是指一个事务先开始读，然后另一个事务则过来执行写操作，&lt;/li&gt;
  &lt;li&gt;写-读则相反，主要是读、写发生的前后顺序的区别。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;并发事务中同时存在读、写两类操作时，这是最容易出问题的场景，脏读、不可重复读、幻读都出自于这种场景中，当有一个事务在做写操作时，读的事务中就有可能出现这一系列问题，因此数据库才会引入各种机制解决。&lt;/p&gt;

&lt;h5 id=&quot;14各场景下解决问题的方案&quot;&gt;1.4、各场景下解决问题的方案&lt;/h5&gt;

&lt;p&gt;在《锁机制》中，对于写-写、读-写、写-读这三类场景，都是利用加锁的方案确保线程安全，但是，加锁会导致部分事务串行化，因此效率会下降，而MVCC机制的诞生则解决了这个问题。写-写场景必须要加锁才能保障安全，因此先将该场景排除在外。&lt;/p&gt;

&lt;p&gt;基于读-写并存的场景，推出了MVCC机制，在线程安全问题和加锁串行化之间做了一定取舍，让两者之间达到了很好的平衡，即防止了脏读、不可重复读及幻读问题的出现，又无需对并发读-写事务加锁处理。&lt;/p&gt;

&lt;h5 id=&quot;总结&quot;&gt;总结&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;读-读：无需并发控制&lt;/li&gt;
  &lt;li&gt;写-写：必须加锁执行串行&lt;/li&gt;
  &lt;li&gt;读-写、写-读：可以引入MVCC机制，在不加锁的情况下，保证并发安全，提升效率&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2mvcc是什么&quot;&gt;&lt;strong&gt;2、MVCC是什么？&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;MVCC，全称是多版本并发控制（Multi-Version Concurrency Control），是一种常用的并发控制方法。它通过在每个读取的数据行中创建数据行的“快照” —— 即该行在事务处理开始时的精确副本，来解决读-写冲突的问题。这样，每个事务读取的都是一致的行数据快照，而不是最新的行版本。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MVCC的目的&lt;/strong&gt;：用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MVCC如何保证并发安全&lt;/strong&gt;：MVCC通过对数据进行多版本保存，根据比较版本号来控制数据是否展示，从而达到读取数据时无需加锁就可以实现事务的隔离性。&lt;/p&gt;

&lt;p&gt;MySQL 是怎么解决幻读的？&lt;/p&gt;

&lt;p&gt;MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了，解决的方案有两种：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;针对&lt;strong&gt;快照读&lt;/strong&gt;（普通 select 语句），是&lt;strong&gt;通过 MVCC 方式解决了幻读&lt;/strong&gt;，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。&lt;/li&gt;
  &lt;li&gt;针对&lt;strong&gt;当前读&lt;/strong&gt;（select … for update 等语句），是&lt;strong&gt;通过 next-key lock（记录锁+间隙锁）方式解决了幻读&lt;/strong&gt;，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3mvcc的实现原理&quot;&gt;&lt;strong&gt;3、MVCC的实现原理&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;MVCC的实现原理主要包括以下几个步骤：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;版本号&lt;/strong&gt;：每个事务开始时，都会被分配一个唯一的事务ID，这个ID同时也是该事务的版本号。对于每一行数据，都会有两个版本号，
    &lt;ul&gt;
      &lt;li&gt;一个是创建版本号，表示创建这行数据的事务的版本号；&lt;/li&gt;
      &lt;li&gt;另一个是删除版本号，表示删除这行数据的事务的版本号。初始时，删除版本号为空。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;读操作&lt;/strong&gt;：当一个事务要读取一行数据时，会检查这行数据的创建版本号和删除版本号。只有当创建版本号小于等于当前事务的版本号，并且删除版本号要么为空，要么大于当前事务的版本号，这行数据才会被当前事务读取。这样可以确保每个事务都是在一致的快照上进行操作。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;写操作&lt;/strong&gt;：当一个事务要修改一行数据时，不会直接覆盖原数据，而是会复制一份新的数据行，然后修改这份新的数据行。新的数据行的创建版本号为当前事务的版本号，删除版本号为空。同时，原数据行的删除版本号会被设置为当前事务的版本号。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;提交事务&lt;/strong&gt;：当一个事务提交时，所有由该事务创建的新数据行的删除版本号都会被设置为无穷大，表示这些数据行现在是可见的。同时，所有被该事务删除的原数据行的删除版本号会被设置为当前事务的版本号，表示这些数据行现在是不可见的。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;垃圾回收&lt;/strong&gt;：为了防止数据版本过多导致的性能问题，需要定期进行垃圾回收。垃圾回收的原则是，只有当没有任何事务会访问到某个数据版本时，这个数据版本才会被回收。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;MVCC的优点是读操作不会被写操作阻塞，写操作也不会被读操作阻塞，大大提高了数据库的并发性能。但是，MVCC也有一些缺点，比如版本链过长会影响读性能，以及需要定期进行垃圾回收等。&lt;/p&gt;

&lt;h5 id=&quot;如何实现&quot;&gt;如何实现？&lt;/h5&gt;

&lt;p&gt;MVCC机制主要通过隐藏字段、Undo-log日志、ReadView这三个东西实现的，其中的多版本主要依赖Undo-log日志来实现，而并发控制则通过表的隐藏字段+ReadView快照来实现。&lt;/p&gt;

&lt;h5 id=&quot;31--undo-log&quot;&gt;3.1  undo log&lt;/h5&gt;

&lt;p&gt;Undo log主要用于事务回滚时恢复原来的数据。mysql在执行sql时，会将一天逻辑相反的日志保存到undo log中。因此，undo log中记录的也是逻辑日志。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;执行Insert语句时，会在undo log日志中记录本次插入的主键id。等事务回滚时，delete删除此id。&lt;/li&gt;
  &lt;li&gt;执行update语句时，MySQL会将修改前的数据保存在undo log中。等事务回滚时，再执行一次update，得到原来的数据。&lt;/li&gt;
  &lt;li&gt;执行delete语句时，会在undo log中保存删除前的数据。等事务回滚时，再执行insert，插入原来的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ReadView要通过undo log链条找到合适自己读取的记录。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.2 隐藏字段&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在数据库的每行上，除了存放真实的数据以外，还存在3个隐藏的列：row_id、trx_id和roll_pointerrow_id，&lt;/p&gt;

&lt;p&gt;row_id，行号：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果当前表有整数类型的主键，那么row_id的值就是主键的值&lt;/li&gt;
  &lt;li&gt;如果没有整数类型的主键，则MySQL会按照字段的顺序选择一个非空的整数类型的唯一索引为row_id&lt;/li&gt;
  &lt;li&gt;如果都没有找到，则会创建一个自动增长的整数作为row_id&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;trx_id，是哪个事务记录的这条log：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当一个事务开始执行前，MySQL就会为这个事务分配一个全局自增的事务id。&lt;/li&gt;
  &lt;li&gt;之后该事务对当前进行的增、改、删除等操作时，都会将自己的事务ID记录到trx_id中，表明是哪个事务修改的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;roll_pointer，回滚指针：undo日志中指向修改之前的的一行记录。当一直有事务对该行改动时，就会一直生成undo log，最终将会形成undo log版本链。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.3&lt;/strong&gt; &lt;strong&gt;ReadView&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ReadView可以被理解为一个过滤器或者说是一个视图，它定义了在当前事务中，哪些数据版本是可见的，哪些数据版本是不可见的。&lt;/p&gt;

&lt;p&gt;具体来说，ReadView包含以下几个重要的信息：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;creator_trx_id：当前事务id&lt;/li&gt;
  &lt;li&gt;m_ids：这是一个列表，包含了在当前事务开始时，所有活跃（即还未提交）的事务的ID。&lt;/li&gt;
  &lt;li&gt;min_trx_id：这是m_ids&lt;strong&gt;列表中&lt;/strong&gt;的最小事务ID。这个ID表示了在当前事务开始时，系统中最早开始的尚未提交的事务ID。&lt;/li&gt;
  &lt;li&gt;max_trx_id：表示生成readview时，系统中应该分配给下一个事务的id值&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;4mvcc如何是运作的&quot;&gt;4、MVCC如何是运作的&lt;/h4&gt;

&lt;p&gt;根据undo log的链中的每一条trx_id与min_trx_id和max_trx_id进行对比：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果小于min_trx_id，说明这个trx_id的log记录就已经事务已经提交过了，完成的事务，创建本事务之前就已经存在的日志，当然可以读。&lt;/li&gt;
  &lt;li&gt;如果大于max_trx_id说明这个版本的数据log是在创建RV之后生成的，不可读。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果是在这之间，查看trx_id是否包含m_ids列表之中：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;不包含说明创建RV之前这个事务已经被提交了，那么是可读的。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;包含说明创建RV的时候，还是活跃（没提交）事务。那么是不可读的，有可能脏读；到了这里说明这条数据的变更版本在RV之内，则要查看creator_trx_id与trx_id是否一致：&lt;/p&gt;
        &lt;ul&gt;
          &lt;li&gt;一致说明就是当前事务创建的；允许使用；&lt;/li&gt;
          &lt;li&gt;否则说明是当前RV的其他事务操作的，不能使用;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;41-可重复读是如何工作的&quot;&gt;&lt;strong&gt;4.1 可重复读是如何工作的？&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;一旦创建是不可变的，即便其他事务提交了，也不会影响当前事务创建的ReadView，你可以理解为一个副本快照。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.2 读已提交是如何工作的？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;读已提交隔离级别是在每次读取数据时，都会生成一个新的Read View。&lt;/p&gt;</content><author><name>Ted</name></author><category term="数据库" /><summary type="html">1、并发事务的四种场景</summary></entry><entry><title type="html">数据库事务</title><link href="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/01/transaction/" rel="alternate" type="text/html" title="数据库事务" /><published>2022-11-01T20:00:00+08:00</published><updated>2022-11-01T20:00:00+08:00</updated><id>http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/01/transaction</id><content type="html" xml:base="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/11/01/transaction/">&lt;h3 id=&quot;1什么是事务&quot;&gt;1、什么是事务&lt;/h3&gt;

&lt;p&gt;所谓事务是用户定义的一个数据库操作序列， 这些操作要么全做，要么全不做，是一个不可分割的工作单位。&lt;/p&gt;

&lt;p&gt;在关系型数据库中，一个事务可以是一条 SQL 语句，一组 SQL 语句或者是整个程序，事务的开始和结束由用户显示控制，如果用户没有显式定义事务，则由 DBMS 按默认规定自动划分事务，如在 MySQL 中默认 autocommit 为 ON 则开启事务自动提交，每条没有显式定义事务的 SQL 语句都会被当作一个单独的事务并自动提交(隐式事务)。&lt;/p&gt;

&lt;p&gt;数据库事务可以确保该事务范围内的所有操作都可以全部成功或者全部失败。如果事务失败，那么效果就和没有执行这些SQL一样，不会对数据库数据有任何改动。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;显式和隐式：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;单条SQL语句，数据库系统自动将其作为一个事务执行，这种事务被称为隐式事务。&lt;/li&gt;
  &lt;li&gt;多条SQL语句作为一个事务执行，使用BEGIN/START TRANSACTION;开启一个事务，使用COMMIT提交一个事务，这种事务被称为显式事务。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;COMMIT和RollBack&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;COMMIT是指提交事务，即试图把事务内的所有SQL所做的修改永久保存。&lt;/li&gt;
  &lt;li&gt;ROLLBACK是对之前的事务操作进行回滚；回滚会结束用户的事务，并撤销正在进行的所有未提交的修改；&lt;/li&gt;
  &lt;li&gt;如果COMMIT失败了，会自动调用ROLLBACK，也就是之前的操作会回滚。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2acid四个特性&quot;&gt;2、ACID四个特性&lt;/h3&gt;

&lt;p&gt;数据库事务具有ACID这4个特性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A：Atomicity，原子性，将所有SQL作为原子工作单元执行，要么全部执行，要么全部不执行；&lt;/li&gt;
  &lt;li&gt;C：Consistency，一致性，事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B账户则必定加上了100；&lt;/li&gt;
  &lt;li&gt;I：Isolation，隔离性，如果有多个事务并发执行，每个事务作出的修改必须与其他事务隔离；&lt;/li&gt;
  &lt;li&gt;D：Durability，持久性，即事务完成后，对数据库数据的修改被持久化存储。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3并发事务导致&quot;&gt;3、并发事务导致&lt;数据不一致&gt;&lt;/数据不一致&gt;&lt;/h3&gt;

&lt;p&gt;并发事务可能导致以下几种数据不一致的情况：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;脏读（Dirty Read）： 脏读指的是一个事务读取了另一个事务尚未提交的数据。如果后续事务回滚，那么之前读取的数据就是无效的，导致数据不一致。&lt;/li&gt;
  &lt;li&gt;不可重复读（Non-repeatable Read）： 不可重复读指的是在同一个事务中，多次读取同一数据时，得到的结果不一致。这是因为在事务执行期间，其他事务修改了该数据。&lt;/li&gt;
  &lt;li&gt;幻读（Phantom Read）： 幻读指的是在同一个事务中，多次查询同一范围的数据时，得到的结果不一致。这是因为在事务执行期间，其他事务插入或删除了符合查询条件的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些数据不一致的情况是由于并发事务之间的交互和修改操作导致的。&lt;/p&gt;

&lt;p&gt;不同的隔离级别可以控制事务之间的相互影响，从而避免或减少这些数据不一致的问题。较高的隔离级别可以提供更强的数据一致性，但可能会降低并发性能。&lt;/p&gt;

&lt;p&gt;为了保证数据的一致性，需要在设计数据库架构和事务处理时，合理选择隔离级别，并使用适当的并发控制机制：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LBCC（Lock-Base Concurrency Control）基于锁的并发控制；&lt;/li&gt;
  &lt;li&gt;MVCC（Multiversion Concurrency Control）多版本并发控制；&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4隔离级别&quot;&gt;4、隔离级别&lt;/h3&gt;

&lt;p&gt;数据库的隔离级别是指多个并发事务之间的隔离程度，用于控制事务之间的相互影响和数据一致性的要求。&lt;/p&gt;

&lt;p&gt;隔离级别定义了一个事务在读取和修改数据时能够看到其他事务的哪些变化。 常见的数据库隔离级别包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;读未提交（Read Uncommitted）： 最低的隔离级别，这种级别实际上是没有做隔离，事务可以读取其他事务尚未提交的数据。这种隔离级别可能导致脏读（Dirty Read），即读取到未提交的数据。&lt;/li&gt;
  &lt;li&gt;读已提交（Read Committed）： 事务只能读取已经提交的数据，避免了脏读。但是在同一个事务中，多次读取同一数据可能会看到不同的结果，因为其他事务可能在事务执行期间修改了数据。&lt;/li&gt;
  &lt;li&gt;可重复读（Repeatable Read）： 事务在执行期间保持一致的快照视图，即事务开始时读取的数据将保持不变。其他事务对数据的修改不会影响当前事务的读取结果。这种隔离级别可以避免脏读和不可重复读（Non-repeatable Read），是MySQL默认级别。&lt;/li&gt;
  &lt;li&gt;串行化（Serializable）： 最高的隔离级别，这种级别实际上是完全隔离，将并发执行的事务串行化。这种隔离级别可以避免脏读、不可重复读和幻读（Phantom Read），但会降低并发性能。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;不同的隔离级别提供了不同的数据一致性和并发性能权衡。较低的隔离级别可以提高并发性能，但可能导致数据不一致。较高的隔离级别可以保证数据一致性，但可能降低并发性能。&lt;/p&gt;

&lt;h3 id=&quot;5这四种隔离级别具体是如何实现的呢&quot;&gt;5、这四种隔离级别具体是如何实现的呢？&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;对于最低级的「读未提交」隔离级别的事务来说，这是没有隔离；&lt;/li&gt;
  &lt;li&gt;对于最高级的「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；&lt;/li&gt;
  &lt;li&gt;对于中间的「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同。
    &lt;ul&gt;
      &lt;li&gt;「读已提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，&lt;/li&gt;
      &lt;li&gt;「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;隔离级别只是定义了在不同的级别下应该保证哪些一致性，具体实现这些隔离级别的方法有很多，如传统的基于锁的并发控制（LBCC），还有一些无锁并发控制方案，如时间戳（timestamp), 乐观控制法（scheduler），多版本并发控制（MVCC）等。&lt;/p&gt;

&lt;h3 id=&quot;6并发控制&quot;&gt;6、并发控制&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;LBCC（Lock-Base Concurrency Control）基于锁的并发控制；&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;所谓封锁就是事务在某个数据对象进行操作之前先申请锁，对该对象加锁后，该事务就拥有了一定的对该对象的控制，在该事务释放该锁前，其他事务不能操作此数据对象。 从锁的模式来看，锁可以分为共享锁和排它锁，共享锁又称为读锁（S 锁），排它锁又称为写锁（X锁）。&lt;/p&gt;

&lt;p&gt;X 锁：若事务 T 对数据对象 A 加上了 X 锁，则只允许 T 读取和修改 A， 其他任何事务不得再对 A加任何类型的锁，直到 T 释放锁，。&lt;/p&gt;

&lt;p&gt;S 锁：若事务 T 对数据对象 A 加上了 S 锁，则 T 和其他事务都可以可以读 A，同时其他事务可以继续申请 A 的 S 锁，但是直到所有事务都释放 A 的 S 锁为止（所有事务并不包括自己），A 是不允许修改的。这就意味着如果只有一个事务对 A 添加了 S 锁，那他自己是可以修改数据的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MVCC（Multiversion Concurrency Control）多版本并发控制&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;通过 LBCC， 我们可以解决所有的并发不一致问题，那为什么还会有其他并发控制方案呢？归根结底还是基于性能的考虑， LBCC 只是实现了允许并发读，但对于并发读写，写写操作只能串行执行，在读写都很频繁的场景下，并发性能将大大降低，因此，人们才提出各种无锁并发控制方案，MVCC 就属于其中一种。&lt;/p&gt;

&lt;p&gt;MVCC 的大概思路是每一个事务都有一个唯一的ID，当某一个事务要修改某行数据时，先将这一行原来的数据做一个快照保存下来，当有其他并发事务也要操作这个事务时，可以操作之前的版本，这样，最新的版本只被写事务维持，不会干扰到读事务，以此实现隔离，MVCC 并没有一个统一的标准，不同 DBS 的实现也不尽相同。&lt;/p&gt;</content><author><name>Ted</name></author><category term="数据库" /><summary type="html">1、什么是事务</summary></entry><entry><title type="html">数据库架构</title><link href="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/09/19/mysql/" rel="alternate" type="text/html" title="数据库架构" /><published>2022-09-19T20:00:00+08:00</published><updated>2022-09-19T20:00:00+08:00</updated><id>http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/09/19/mysql</id><content type="html" xml:base="http://www.helloted.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2022/09/19/mysql/">&lt;h3 id=&quot;一mysql架构&quot;&gt;一、MySQL架构&lt;/h3&gt;

&lt;p&gt;MySQL 的架构共分为两层：&lt;strong&gt;Server 层、存储引擎层：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Server 层负责建立连接、分析和执行 SQL。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。&lt;/li&gt;
  &lt;li&gt;存储引擎层负责数据的存储和提取。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，从 MySQL 5.5 版本开始， InnoDB 成为了 MySQL 的默认存储引擎。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 ，且是默认使用，也就是说在数据表中创建的主键索引和二级索引默认使用的是 B+ 树索引。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;执行一条 SQL 查询语句，期间发生了什么？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;连接器：建立连接，管理连接、校验用户身份；&lt;/li&gt;
  &lt;li&gt;查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；&lt;/li&gt;
  &lt;li&gt;解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；&lt;/li&gt;
  &lt;li&gt;执行 SQL：执行 SQL 共有三个阶段：
    &lt;ul&gt;
      &lt;li&gt;预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。&lt;/li&gt;
      &lt;li&gt;优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；&lt;/li&gt;
      &lt;li&gt;执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/53.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1连接器&quot;&gt;&lt;strong&gt;1、连接器&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;MySQL 是基于 TCP 协议进行传输的。&lt;/p&gt;

&lt;p&gt;连接器的工作：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;与客户端进行 TCP 三次握手建立连接；&lt;/li&gt;
  &lt;li&gt;校验客户端的用户名和密码，如果用户名或密码不对，则会报错；&lt;/li&gt;
  &lt;li&gt;如果用户名和密码都对了，会读取该用户的权限，然后后面的权限逻辑判断都基于此时读取到的权限；&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;如何查看 MySQL 服务被多少个客户端连接了？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;可以执行 show processlist 命令进行查看。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;空闲连接会一直占用着吗？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;MySQL 定义了空闲连接的最大空闲时长，由 wait_timeout 参数控制的，默认值是 8 小时（28880秒），如果空闲连接超过了这个时间，连接器就会自动将它断开。&lt;/p&gt;

&lt;p&gt;手动断开空闲的连接，使用的是 kill connection + id 的命令。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;MySQL 的连接数有限制吗？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;MySQL 服务支持的最大连接数由 max_connections 参数控制，比如我的 MySQL 服务默认是 151 个,超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。&lt;/p&gt;

&lt;p&gt;长连接和短连接、连接池&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;短连接&lt;/strong&gt;就是我们开发的应用程序需要访问数据库时候，需要建立数据连接，执行SQL操作，关闭连接。简单讲就是每一次操作数据库，都要执行一次上述操作。它的弊端就是：如果网络速度不是很理想的情况下，短连接的会消耗大量的系统资源，在生产环境中，业务很多的话，可能 1 秒内几千个连接，如果都是短连接，且 sql 处理慢的话，连接关闭不及时，那么资源耗尽速度可能发生在几分钟甚至几秒，所以我们系统不大可能一直是短连接。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;长连接&lt;/strong&gt;是指我们的程序和数据库连接之后，就一直打开，后面程序来访问相同数据库就复用该连接，使用长连接主要是考虑到减少短连接连接的开销，但是从服务器端来看，维持一个连接会占用服务器内存，如果所有程序都是长连接，肯定会有部分连接处于闲置状态，但是无论什么状态连接，都占用内存，这会造成服务器端的资源浪费，也显得不是很高效。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;连接池&lt;/strong&gt;，它是一个预先创建的连接缓冲池，考虑到某些数据进行连接之后，处理时间过长，而不想它闲置，允许给其他线程使用。一般现在的应用服务器都带有连接池组件，允许应用程序，客户端来连接，应用服务器维护着连接池的整个生命周期。数据库连接池技术的思想非常简单，将数据库连接作为对象存储在一个Vector对象中，一旦数据库连接建立后，不同的数据库访问请求就可以共享这些连接，这样，通过复用这些已经建立的数据库连接，可以克服无论长连接和短连接缺点，极大地节省系统资源和时间&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;怎么解决长连接占用内存的问题？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;定期断开长连接。既然断开连接后就会释放连接占用的内存资源，那么我们可以定期断开长连接。&lt;/li&gt;
  &lt;li&gt;客户端主动重置连接。&lt;/li&gt;
  &lt;li&gt;连接池&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2查询缓存&quot;&gt;&lt;strong&gt;2、查询缓存&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;MySQL 8.0 版本之后没有查询缓存这一步了。&lt;/p&gt;

&lt;p&gt;连接器得工作完成后，客户端就可以向 MySQL 服务发送 SQL 语句了，MySQL 服务收到 SQL 语句后，就会解析出 SQL 语句的第一个字段，看看是什么类型的语句。&lt;/p&gt;

&lt;p&gt;如果 SQL 是查询语句（select 语句），MySQL 就会先去查询缓存（ Query Cache ）里查找缓存数据，看看之前有没有执行过这一条命令，这个查询缓存是以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果。如果查询的语句命中查询缓存，那么就会直接返回 value 给客户端。如果查询的语句没有命中查询缓存中，那么就要往下继续执行，等执行完后，查询的结果就会被存入查询缓存中。&lt;/p&gt;

&lt;p&gt;真实情况是查询缓存挺鸡肋的。对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，相当于缓存了个寂寞。&lt;/p&gt;

&lt;p&gt;所以，MySQL 8.0 版本直接将查询缓存删掉了，也就是说 MySQL 8.0 开始，执行一条 SQL 查询语句，不会再走到查询缓存这个阶段了。这里说的查询缓存是 server 层的，也就是 MySQL 8.0 版本移除的是 server 层的查询缓存，并不是 Innodb 存储引擎中的 buffer pool。&lt;/p&gt;

&lt;h4 id=&quot;3解析-sql&quot;&gt;&lt;strong&gt;3、解析 SQL&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;在正式执行 SQL 查询语句之前， MySQL 会先对 SQL 语句做解析，这个工作交由「解析器」来完成。&lt;/p&gt;

&lt;p&gt;解析器会做如下两件事情。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;词法分析。MySQL 会根据你输入的字符串识别出关键字出来&lt;/li&gt;
  &lt;li&gt;语法分析。根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法，如果没问题就会构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;4执行-sql&quot;&gt;&lt;strong&gt;4、执行 SQL&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;经过解析器后，接着就要进入执行 SQL 查询语句的流程了，每条SELECT 查询语句流程主要可以分为下面这三个阶段：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;prepare 阶段，也就是预处理阶段；&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;检查 SQL 查询语句中的表或者字段是否存在；&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;将 select * 中的 * 符号，扩展为表上的所有列；&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;optimize 阶段，也就是优化阶段：优化器主要负责将 SQL 查询语句的执行方案确定下来，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。&lt;/li&gt;
  &lt;li&gt;execute 阶段，也就是执行阶段：真正开始执行语句了，这个工作是由「执行器」完成的。在执行的过程中，执行器就会和存储引擎交互了，交互是以记录为单位的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二innodb架构&quot;&gt;二、InnoDB架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/Simple_2/52.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;InnoDB整体也分为三层：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;内存结构&lt;/strong&gt;(In-Memory Structure)，这一层在MySQL服务进程内；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;OS Cache&lt;/strong&gt;，这一层属于内核态内存；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;磁盘结构&lt;/strong&gt;(On-Disk Structure)，这一层在文件系统上；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这三层的交互有两类：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;直接O_Direct落地数据（长途中，长箭头）：Buffer Pool的数据与磁盘数据；&lt;/li&gt;
  &lt;li&gt;通过OS Cache落地数据（上图中，两个短箭头）：Log Buffer；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;内存区域&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;InnoDB内存结构包含&lt;strong&gt;四大核心组件&lt;/strong&gt;，分别是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;缓冲池&lt;/strong&gt;(Buffer Pool):加速&lt;strong&gt;读&lt;/strong&gt;请求，避免每次数据访问都进行磁盘IO，起到Redis缓存的作用。涉及的技术点包括：预读，局部性原理，LRU，预读失败+缓冲池污染，新生代老生代双链LRU&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;更改缓冲区&lt;/strong&gt;(Change Buffer)：为了插入或者更新次要索引而存在，是Buffer Pool的一部分，当辅助索引页不在缓冲池中时，更改缓冲区负责缓存对这些页的更改。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;自适应哈希索引&lt;/strong&gt;(Adaptive Hash Index)：用于优化某些读取选项的性能。它旨在通过提供快速的内存查找机制来加速对频繁查询的索引页的访问，&lt;strong&gt;加速读请求&lt;/strong&gt;，减少索引查询的寻路路径。涉及的技术点包括：&lt;strong&gt;聚集索引，普通索引，哈希索引&lt;/strong&gt;；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;日志缓冲区&lt;/strong&gt;(Log Buffer)：保存要写入事务日志的更改的内存区域，日志缓冲区通过在定期将日志刷新到磁盘上的重做日志之前将日志写入内存来提高性能，并提供了高并发与强一致性的折衷方案。涉及的技术点包括：&lt;strong&gt;redo log作用，流程，三层架构，随机写优化为顺序写，次次写优化为批量写&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;文件区域:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;系统表空间(System tablespace)&lt;/strong&gt;：用作更改缓冲区的存储区域。InnoDB 使用一个或多个数据文件作为系统表空间。ibdata1默认情况下，MySQL在数据目录中创建该文件。启动选项innodb_data_file_path决定系统表空间数据文件的大小和数量。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;每表文件表空间(File-per-table tablespaces)&lt;/strong&gt;:存储 InnoDB 表的实际数据。当您使用 InnoDB 存储引擎创建新表时，InnoDB 将每个表及其关联索引存储在一个扩展名为 file-per-tablespace 的文件中.ibd。例如，如果您创建一个名为tbl_name的表，InnoDB 将在数据目录中tbl_name创建一个相应的 file-per-tablespace 数据文件。tbl_name.idb&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;通用表空间(General tablespaces)&lt;/strong&gt;：可以存储多个表的共享表空间。通用表空间都是使用该CREATE TABLESPACE语句创建的。当多个表共享相同的通用表空间时，通用表空间有助于减少内存中表空间元数据的重复。因此，与每表文件表空间相比，通用表空间具有潜在的内存优势。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Undo表空间(Undo tablespaces):&lt;/strong&gt;存储撤消日志，其中包含撤消事务的最新更改的信息。MySQL 有两个默认的撤消表空间文件innodb_undo_001 和innodb_undo_002.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;临时表空间(Temporary tablespaces):&lt;/strong&gt;当您创建临时表时，InnoDB 将它们存储在临时表空间中，更具体地说是会话临时表空间中。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;双写缓冲区(Doublewrite buffer)：&lt;/strong&gt;InnoDB 使用 Doublewrite Buffer 来存储在实际写入 InnoDB 数据文件之前已从缓冲池中刷新的页面。允许 InnoDB 检索可靠的页面副本，以便在发生存储问题时进行恢复。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;重做日志(Redo log)&lt;/strong&gt;：用于存储对表所做的更改。InnoDB在崩溃恢复期间使用重做日志来纠正不完整事务写入的数据。例如，当您执行更改数据库的 SQL 语句（例如INSERT、UPDATE和DELETE ）时，重做日志会将请求存储在重做日志文件中。如果发生崩溃，MySQL 会重播重做日志中在接受连接之前未完成的修改。InnoDB 使用一组重做日志文件（ib_logfile0、iblogfile1、 …）来存储对表数据的更改。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;撤消日志(Undo logs)&lt;/strong&gt;：存储回滚操作所需的信息。例如，如果您执行一个事务并决定回滚它，InnoDB将利用撤消日志来撤销该事务期间所做的更改。InnoDB 使用一组撤消日志文件（通常命名为undo_001.ibd、udo_002.ibd等）来存储日志。&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ted</name></author><category term="数据库" /><summary type="html">一、MySQL架构</summary></entry></feed>